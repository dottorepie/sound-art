///// basis matter cloud drone argumrent structure// no pan





///////MELODIC SEQUEBCE ARGUMENTS////control cycle moves

///tone = note on a melodic sequence derivem from location coordinate of the sequence/// each coordinate is three bars of x,x,x,x| y,y,y,y | z,z,z,z
/// the amount of xs,ys anz zs depends on the rhythm polyhedron. Tonal value can also be deriven simply be location magnitude.

////phase = angle phase of respective tone, x,y ,z according to location coordinate

/////amp = reciprocal of tone in a melodic sequence



////GENERAL DRONE ARGUMENTS

///fund = pitch according to universe timeline, starting from high pitch at big bang, towadrds low pitch at heatdeath, source: composition envelope

////gain = reciprocal of fund scalar, source: composition envelope

/////bank = amount of astral objects present (points) at a given cosmic level (matter cloud , star, galaxy, sun)
///this corellates to amount of bandpass peaks/slopes present on the drone
///, source: composition timeline and point of spectation

////m = spherical harmonic state of a given astral object
/// at a given astral objects the magnitudes of points set the freq
///, source: envelope in order to composition timeline and point of spectation

////m_angles = modulation speed of spherical harmonic at a given state in time, source: automaton in order to timeline

////low = at a given location, amount of depth points scales amount of sawooth present
///, source: magnitude in order of composition timeline and point of spectation

////band = the modulation speed of the spectrum (band pass slopes and peaks), source: automaton in order of point/object of spectation

////rq = the width of the bandpass modulation wave peakes
///(if this spectrum modulation is to be seen as a wave,
///the pediod of this wave is a combined result of the waveform width and the sweep of this width across the spectrum)
///one type of spectrum comenssation would be to have a generic rq
//and a rq scalar for the location of the sweep on the spectrum, eg. at low frequencies rq should be lower and at high frequencies higher

////mix = amount of reverbaration (can come from amp along with eq)

////room =size of reverbaration room  (can come from amp along with eq)



///CONTROL AND INTERACTION AS INSTALLATION

//randomness generators = noise and random number generators or simple lfo modulators that can modulate the control cycle Î±and other cosmographic parameters under envelopes, routines and patterns

//ambisonic microphone = amplitude follower of b-formast signal to control sphere modulation

//theremin = electromagnetic field amplitude follower as modulation source/// possible use: interaction of the audience with tha algorithm, eg.
//modulating overall gain from silence to full gain, or some other cosmogaphic parameter like shift from one galaxy to another etc.
///other possible use similar as ambisonic mic.

// photocell= space brightness amplitude follower as modulation source////  possible use: cosmic envelope(if light change is slow, eg. the daytime)
/// if in enclosed space, light change is synthetic so photocell becomes essentially an type of immersive modulator for parts of the cosmography and overall gain (like shutting lights of shuts sound down but not hardware output, switching one, bings back sound level to audible)
///other possible use similar as ambisonic mic.



///recap

///photocell: composition on off switch
///theremin/ electromagnet: spectator interaction
//ambisonic mic: control sphere modulator and thus melodic sequence instantiator, reciprocal amlitude follower or normal, audence silence=melody, audience sound=no melody, or the inverse, depending on exhibition setting.
///randomness/noise/lfos: composition automata





////SPECTATION

///the drone is the cloud matter array as a whole
//a melodic sequence is a sequence of points, in order to control sphere movement coordinate sequence, on an array

//spectation is which array is output for the melodic sequence and how the object of the array affects the drone timbre in bottom up architecture
//bottom up means that the final value output for the above mentioned parameters is the products of the material arrays nesting.
/// that is a galaxy ot star is nested in the matter cloud array, following a sun and solar system is nested in a galaxy.

//so essentially whatever array is the object of spectation it contains all previous nesting arrays information for melody and timbre

//so spectation is a choice of solar system/sun in a galaxy/star in the cloud matter array
/// it is understandable that the existance of any of these arrays and their possible spectation depends on the timeline

//concluding there should be two types of choice control (like the control sphere and its silver star)
//one for melody with its rhythm polytope and one for localization in the universe.
//for instance the localization control sets a sequence of locations on the cloudmatter array, then a sub routine control can set a location on this
//chosen cluster of the cloud (star) and so on
///the second cotrol for melodic sequencies just creates a melody sequence on the, from the localization control source, array at some point in time, with the previous arrays on the nesting as types of funamental scalars on the final objects tonal melodic sequence.


///so the melody control is an abstract control sphere which is atemporal and aspacial (meaning its form of choice does not depend on the state of the timeline or what object is spectated) it just gets shaped accordingly

///the control sphere of localization is a set of nested choices that map to different regions in space and the further arrays these regions contain.
//for example an initial choice would be point n, then if that point (according to timeline) is a star, drone timbre will be according. If that star
//has become a galaxy, then a second choice has to be made whereas points on the galaxy represent suns, the choice of which also affects timbre accordingly, and as a product with the previous timbre affection from the chosen galaxy.

//the melody control has to represent free will so it is matter of interaction of performance in terms of installation
///the localization control is an automaton that randomly chooses regions of space for some interval, like a generative type of choice and subchoice
//of a cloud

//panning output and VBAP is irrelevant for spectation as defalut, but its choice mono, stereo or spatial can have the corresponding
//aesthetic and immersion characteristics as well as value demand, eg. as long as there is a panning environment, stereo or spatial,
//a chosen location has to be maped to panning location, with some array as default, being the matter cloud, with no product from further nested arrays//
//for phases this is not the case as their value can be the product of all nesting of choice of localization.
///ig. in the case of VBAP if the matter cloud, represents locations on the VBAP array, then sub locations on the matter cloud array///
//like a galaxy do not affect the initial panning location on the VBAP.
///But this can be further developed by modulated the poanning spread, for example a matter cloud location can have a wide spread, and
///as the localization goes further to sublocations the spread can be minimized, thus creating a kind of fish eye view topography landscape
//painting of the universe.

//Of course paning in case of mono outout is irrelevant.



	